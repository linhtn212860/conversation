# ğŸ“š Giáº£i thÃ­ch chi tiáº¿t code `chat_optimized.py`

## ğŸ“‹ Má»¥c lá»¥c
1. [Import thÆ° viá»‡n](#1-import-thÆ°-viá»‡n)
2. [Cáº¥u hÃ¬nh](#2-cáº¥u-hÃ¬nh)
3. [System Prompt](#3-system-prompt)
4. [Load Model](#4-load-model)
5. [Web Search](#5-web-search)
6. [Search Intent Detection](#6-search-intent-detection)
7. [Streaming Generation](#7-streaming-generation)
8. [Chat Function](#8-chat-function)
9. [Main Loop](#9-main-loop)

---

## 1. Import thÆ° viá»‡n

```python
import torch                    # Framework deep learning cá»§a Facebook
import re                       # Regular expressions - tÃ¬m pattern trong text
from pathlib import Path        # Xá»­ lÃ½ Ä‘Æ°á»ng dáº«n file (hoáº¡t Ä‘á»™ng trÃªn má»i OS)
from datetime import datetime   # Láº¥y ngÃ y giá» hiá»‡n táº¡i
from threading import Thread    # Cháº¡y code song song (cho streaming)
```

### Transformers imports:
```python
from transformers import (
    AutoModelForCausalLM,      # Tá»± Ä‘á»™ng chá»n class model phÃ¹ há»£p (Qwen, Llama, etc.)
    AutoTokenizer,              # Chuyá»ƒn text <-> sá»‘ (tokens)
    TextIteratorStreamer,       # Cho phÃ©p Ä‘á»c output tá»«ng pháº§n
    BitsAndBytesConfig          # Cáº¥u hÃ¬nh nÃ©n model (4-bit/8-bit)
)
```

---

## 2. Cáº¥u hÃ¬nh

```python
MODEL_PATH = Path(__file__).parent / "models" / "Qwen_Qwen3-8B"
# __file__ = Ä‘Æ°á»ng dáº«n file python hiá»‡n táº¡i
# .parent = thÆ° má»¥c chá»©a file
# / "models" = ná»‘i thÃªm thÆ° má»¥c models
# Káº¿t quáº£: /home/.../qwen_8b/models/Qwen_Qwen3-8B

CURRENT_DATE = datetime.now().strftime("%d/%m/%Y")
# datetime.now() = thá»i Ä‘iá»ƒm hiá»‡n táº¡i
# strftime() = format thÃ nh string
# "%d/%m/%Y" = 06/01/2026
```

---

## 3. System Prompt

System prompt Ä‘á»‹nh nghÄ©a "nhÃ¢n cÃ¡ch" cá»§a AI. CÃ¡c Ä‘iá»ƒm quan trá»ng:

### Táº¡i sao cáº§n `[SEARCH:]`?
Model cÃ³ **knowledge cutoff** (giá»›i háº¡n kiáº¿n thá»©c) - khÃ´ng biáº¿t gÃ¬ sau thá»i Ä‘iá»ƒm training.
VÃ­ dá»¥: Model train nÄƒm 2024, khÃ´ng biáº¿t ai tháº¯ng Ballon d'Or 2025.

### Language
This project is tuned for English conversational responses.

---

## 4. Load Model

### 4-bit Quantization lÃ  gÃ¬?

```
BÃ¬nh thÆ°á»ng: má»—i tham sá»‘ = 32 bit (float32)
4-bit:       má»—i tham sá»‘ = 4 bit

Model Qwen3-8B cÃ³ 8 tá»· tham sá»‘:
- Float32: 8B Ã— 4 bytes = 32 GB VRAM cáº§n thiáº¿t
- Float16: 8B Ã— 2 bytes = 16 GB VRAM
- 4-bit:   8B Ã— 0.5 bytes = 4 GB VRAM âœ…
```

### Code giáº£i thÃ­ch:

```python
quantization_config = BitsAndBytesConfig(
    load_in_4bit=True,                    # Báº­t 4-bit
    bnb_4bit_compute_dtype=torch.bfloat16, # Kiá»ƒu dá»¯ liá»‡u khi tÃ­nh toÃ¡n
    bnb_4bit_use_double_quant=True,       # NÃ©n 2 láº§n (tiáº¿t kiá»‡m thÃªm)
    bnb_4bit_quant_type="nf4"             # NormalFloat4 - phÆ°Æ¡ng phÃ¡p nÃ©n tá»‘t nháº¥t
)

model = AutoModelForCausalLM.from_pretrained(
    str(MODEL_PATH),
    quantization_config=quantization_config,
    device_map="auto",     # Tá»± Ä‘á»™ng phÃ¢n bá»• lÃªn GPU/CPU
    trust_remote_code=True, # Cho phÃ©p cháº¡y code trong model (cáº§n cho Qwen)
    local_files_only=True   # Chá»‰ load tá»« local, khÃ´ng download
)
```

---

## 5. Web Search

### DuckDuckGo Search:

```python
with DDGS() as ddgs:
    # DDGS = DuckDuckGo Search client
    # with ... as = context manager (tá»± Ä‘á»™ng cleanup)
    
    results = list(ddgs.text(query, region='us-en', max_results=3))
    # ddgs.text() = tÃ¬m kiáº¿m web
    # region='us-en' = Æ°u tiÃªn káº¿t quáº£ tiáº¿ng Anh
    # max_results=3 = chá»‰ láº¥y 3 káº¿t quáº£ (nhanh hÆ¡n)
```

### Táº¡i sao dÃ¹ng DuckDuckGo?
- âœ… Miá»…n phÃ­
- âœ… KhÃ´ng cáº§n API key
- âœ… KhÃ´ng tracking
- âœ… PhÃ¹ há»£p cho truy váº¥n tiáº¿ng Anh

---

## 6. Search Intent Detection

### 2 cÃ¡ch phÃ¡t hiá»‡n khi cáº§n search:

#### CÃ¡ch 1: Keyword-based (tá»« khÃ³a cá»‘ Ä‘á»‹nh)
```python
keywords = {
    'weather': ['thá»i tiáº¿t', 'weather', ...],
    'news': ['tin tá»©c', 'chÃ­nh trá»‹', ...],
    ...
}

for search_type, kws in keywords.items():
    if any(kw in user_lower for kw in kws):
        # any() = True náº¿u cÃ³ Báº¤T Ká»² tá»« khÃ³a nÃ o match
        return True, search_type, query
```

#### CÃ¡ch 2: Model-initiated (model tá»± quyáº¿t Ä‘á»‹nh)
```python
search_pattern = r'\[SEARCH:\s*([^\]]+)\]'
# \[SEARCH:  = chuá»—i "[SEARCH:"
# \s*        = 0 hoáº·c nhiá»u khoáº£ng tráº¯ng
# ([^\]]+)   = capture group: báº¥t ká»³ kÃ½ tá»± nÃ o NGOáº I TRá»ª ]
# \]         = kÃ½ tá»± ]

match = re.search(search_pattern, response)
if match:
    query = match.group(1)  # Láº¥y ná»™i dung trong ngoáº·c
```

---

## 7. Streaming Generation â­ QUAN TRá»ŒNG

### Váº¥n Ä‘á»:
BÃ¬nh thÆ°á»ng, `model.generate()` cháº¡y Ä‘áº¿n khi **XONG HOÃ€N TOÃ€N** má»›i return.
â†’ User pháº£i chá» 10-30 giÃ¢y má»›i tháº¥y gÃ¬.

### Giáº£i phÃ¡p: Streaming
```
Thread 1 (main):     [Äá»c token] -> [In ra] -> [Äá»c token] -> [In ra] ...
                           â†‘                        â†‘
                           |                        |
Thread 2 (generate): [Generate] -> [Push token] -> [Generate] -> [Push token] ...
```

### Code giáº£i thÃ­ch:

```python
# 1. Táº¡o streamer (hÃ ng Ä‘á»£i giá»¯a 2 threads)
streamer = TextIteratorStreamer(
    tokenizer, 
    skip_prompt=True,        # Bá» qua input, chá»‰ láº¥y output
    skip_special_tokens=True # Bá» cÃ¡c token Ä‘áº·c biá»‡t
)

# 2. Cáº¥u hÃ¬nh generation
generation_kwargs = dict(
    **inputs,                      # Input tokens
    max_new_tokens=512,            # Tá»‘i Ä‘a 512 tokens output
    do_sample=True,                # Sampling (khÃ´ng deterministic)
    temperature=0.7,               # 0=ráº¥t cháº¯c cháº¯n, 1=ráº¥t ngáº«u nhiÃªn
    top_p=0.9,                     # Nucleus sampling
    streamer=streamer              # QUAN TRá»ŒNG: gáº¯n streamer vÃ o
)

# 3. Cháº¡y generation á»Ÿ thread riÃªng
thread = Thread(target=model.generate, kwargs=generation_kwargs)
thread.start()  # Báº¯t Ä‘áº§u generate á»Ÿ background

# 4. Äá»c tokens tá»« streamer (main thread)
for new_text in streamer:
    # Má»—i láº§n loop = nháº­n Ä‘Æ°á»£c 1 Ä‘oáº¡n text má»›i
    print(new_text, end="", flush=True)  # In ngay láº­p tá»©c
    response += new_text

thread.join()  # Äá»£i thread káº¿t thÃºc
```

### Táº¡i sao cáº§n `flush=True`?
- Máº·c Ä‘á»‹nh Python buffer output, chá» Ä‘á»§ nhiá»u rá»“i in 1 láº§n
- `flush=True` = in ngay láº­p tá»©c, khÃ´ng chá»

---

## 8. Chat Function

### Flow xá»­ lÃ½:

```
User input
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Keyword detection   â”‚â”€â”€â”€ Match? â”€â”€â†’ Search ngay
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚ KhÃ´ng match
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Generate response   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Check [SEARCH:]     â”‚â”€â”€â”€ CÃ³? â”€â”€â†’ Search + Regenerate
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚ KhÃ´ng cÃ³
    â–¼
  Return response
```

---

## 9. Main Loop

```python
while True:  # VÃ²ng láº·p vÃ´ háº¡n
    try:
        user_input = input("ğŸ‘¤ You: ")  # Chá» user nháº­p
        
        # Xá»­ lÃ½ lá»‡nh Ä‘áº·c biá»‡t
        if user_input.lower() == 'quit':
            break  # ThoÃ¡t vÃ²ng láº·p
        
        # ThÃªm vÃ o history
        conversation_history.append({"role": "user", "content": user_input})
        
        # Generate response
        response = chat_with_streaming(...)
        
        # ThÃªm response vÃ o history
        conversation_history.append({"role": "assistant", "content": response})
        
    except KeyboardInterrupt:  # Ctrl+C
        break
    except Exception as e:     # Báº¥t ká»³ lá»—i nÃ o
        print(f"Error: {e}")
        continue  # Tiáº¿p tá»¥c vÃ²ng láº·p, khÃ´ng crash
```

---

## ğŸ“Š Tá»•ng káº¿t Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER INPUT                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. KEYWORD DETECTION                                         â”‚
â”‚     - CÃ³ tá»« khÃ³a "thá»i tiáº¿t", "tin tá»©c", etc.?               â”‚
â”‚     - CÃ³ â†’ Web Search â†’ Augment input                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. APPLY CHAT TEMPLATE                                       â”‚
â”‚     - Chuyá»ƒn messages thÃ nh format model hiá»ƒu                â”‚
â”‚     - System + User messages â†’ Qwen format                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. STREAMING GENERATION                                      â”‚
â”‚     - Thread 1: model.generate() á»Ÿ background                â”‚
â”‚     - Thread 2: in tá»«ng token ra mÃ n hÃ¬nh                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. POST-PROCESS                                              â”‚
â”‚     - Kiá»ƒm tra [SEARCH:] trong response                      â”‚
â”‚     - Náº¿u cÃ³ â†’ Search + Regenerate                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. UPDATE HISTORY                                            â”‚
â”‚     - ThÃªm user message + assistant response vÃ o history     â”‚
â”‚     - History Ä‘Æ°á»£c giá»¯ cho cÃ¡c lÆ°á»£t chat tiáº¿p theo           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## â“ FAQ

### Q: Táº¡i sao cáº§n `trust_remote_code=True`?
A: Má»™t sá»‘ model (nhÆ° Qwen) cÃ³ code custom trong repo. Flag nÃ y cho phÃ©p cháº¡y code Ä‘Ã³.

### Q: `device_map="auto"` lÃ m gÃ¬?
A: Tá»± Ä‘á»™ng phÃ¢n bá»• model lÃªn GPU. Náº¿u khÃ´ng Ä‘á»§ VRAM, sáº½ dÃ¹ng cáº£ CPU.

### Q: Táº¡i sao dÃ¹ng `bfloat16` thay vÃ¬ `float16`?
A: `bfloat16` cÃ³ range sá»‘ lá»›n hÆ¡n, Ã­t bá»‹ overflow khi training/inference.

### Q: Streaming cÃ³ lÃ m cháº­m tá»•ng thá»i gian khÃ´ng?
A: KhÃ´ng! Tá»•ng thá»i gian giá»‘ng nhau, nhÆ°ng user tháº¥y response sá»›m hÆ¡n nhiá»u.
