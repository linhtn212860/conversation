#!/usr/bin/env python3
"""
Interactive continuous chat with Qwen3-8B model.
Maintains conversation history for multi-turn dialogue.
Supports web search for real-time information lookup.
"""

import torch
import re
from pathlib import Path
from datetime import datetime
from transformers import AutoModelForCausalLM, AutoTokenizer

# Optional: Web search
try:
    from ddgs import DDGS
    WEB_SEARCH_AVAILABLE = True
except ImportError:
    try:
        from duckduckgo_search import DDGS
        WEB_SEARCH_AVAILABLE = True
    except ImportError:
        WEB_SEARCH_AVAILABLE = False
        print("‚ö†Ô∏è ƒê·ªÉ s·ª≠ d·ª•ng t√≠nh nƒÉng tra c·ª©u web, h√£y c√†i ƒë·∫∑t: pip install ddgs")

# Model path
MODEL_PATH = Path(__file__).parent / "models" / "Qwen_Qwen3-8B"

# Current date for context
CURRENT_DATE = datetime.now().strftime("%d/%m/%Y")

# System prompt for home robot with web search capability (Bilingual)
SYSTEM_PROMPT = f"""You are a friendly and helpful home assistant robot. Today is {CURRENT_DATE}.

LANGUAGE RULES:
- If the user speaks Vietnamese, respond in Vietnamese
- If the user speaks English, respond in English
- Match the user's language in your responses

You can search for information from the internet when needed. When you need to search for new information or news, start your response with:
[SEARCH: search keywords]

Guidelines:
- Respond naturally like a caring family member
- Keep responses concise and conversational
- Be warm and empathetic when needed
- Use [SEARCH: ...] when you need current news, weather, prices, latest events
- Do not use [SEARCH] for general questions that don't need real-time information

---

B·∫°n l√† m·ªôt robot tr·ª£ l√Ω gia ƒë√¨nh th√¢n thi·ªán v√† h·ªØu √≠ch. H√¥m nay l√† ng√†y {CURRENT_DATE}.

QUY T·∫ÆC NG√îN NG·ªÆ:
- N·∫øu ng∆∞·ªùi d√πng n√≥i ti·∫øng Vi·ªát, tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát
- N·∫øu ng∆∞·ªùi d√πng n√≥i ti·∫øng Anh, tr·∫£ l·ªùi b·∫±ng ti·∫øng Anh
- Ph√π h·ª£p v·ªõi ng√¥n ng·ªØ c·ªßa ng∆∞·ªùi d√πng trong c√¢u tr·∫£ l·ªùi

H∆∞·ªõng d·∫´n:
- Tr·∫£ l·ªùi t·ª± nhi√™n nh∆∞ m·ªôt th√†nh vi√™n gia ƒë√¨nh quan t√¢m
- Gi·ªØ c√¢u tr·∫£ l·ªùi ng·∫Øn g·ªçn v√† mang t√≠nh ƒë·ªëi tho·∫°i
- ·∫§m √°p v√† ƒë·ªìng c·∫£m khi c·∫ßn thi·∫øt"""


def load_model():
    """Load Qwen3-8B model and tokenizer."""
    print(f"üîÑ ƒêang t·∫£i model t·ª´ {MODEL_PATH}...")
    
    tokenizer = AutoTokenizer.from_pretrained(
        str(MODEL_PATH),
        trust_remote_code=True,
        local_files_only=True
    )
    
    model = AutoModelForCausalLM.from_pretrained(
        str(MODEL_PATH),
        torch_dtype=torch.bfloat16,
        device_map="auto",
        trust_remote_code=True,
        local_files_only=True
    )
    
    print("‚úÖ Model ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!\n")
    return model, tokenizer


def web_search(query: str, max_results: int = 5) -> str:
    """Search the web using DuckDuckGo and return formatted results."""
    if not WEB_SEARCH_AVAILABLE:
        return "‚ùå T√≠nh nƒÉng t√¨m ki·∫øm web ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t."
    
    try:
        print(f"üîç ƒêang t√¨m ki·∫øm: {query}")
        with DDGS() as ddgs:
            results = list(ddgs.text(query, region='vn-vi', max_results=max_results))
        
        if not results:
            return f"Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ cho: {query}"
        
        # Format results
        formatted = f"üì∞ K·∫æT QU·∫¢ T√åM KI·∫æM cho '{query}':\n\n"
        for i, r in enumerate(results, 1):
            title = r.get('title', 'Kh√¥ng c√≥ ti√™u ƒë·ªÅ')
            body = r.get('body', 'Kh√¥ng c√≥ m√¥ t·∫£')
            formatted += f"{i}. **{title}**\n   {body}\n\n"
        
        return formatted
    except Exception as e:
        return f"‚ùå L·ªói khi t√¨m ki·∫øm: {e}"


def search_news(topic: str = "Vi·ªát Nam", max_results: int = 5) -> str:
    """Search for latest news."""
    if not WEB_SEARCH_AVAILABLE:
        return "‚ùå T√≠nh nƒÉng t√¨m ki·∫øm web ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t."
    
    try:
        print(f"üì∞ ƒêang t√¨m tin t·ª©c: {topic}")
        with DDGS() as ddgs:
            results = list(ddgs.news(topic, region='vn-vi', max_results=max_results))
        
        if not results:
            return f"Kh√¥ng t√¨m th·∫•y tin t·ª©c cho: {topic}"
        
        # Format results
        formatted = f"üì∞ TIN T·ª®C M·ªöI NH·∫§T v·ªÅ '{topic}':\n\n"
        for i, r in enumerate(results, 1):
            title = r.get('title', 'Kh√¥ng c√≥ ti√™u ƒë·ªÅ')
            body = r.get('body', 'Kh√¥ng c√≥ m√¥ t·∫£')
            date = r.get('date', '')
            source = r.get('source', 'Ngu·ªìn kh√¥ng x√°c ƒë·ªãnh')
            formatted += f"{i}. **{title}**\n   üìÖ {date} | üìå {source}\n   {body}\n\n"
        
        return formatted
    except Exception as e:
        return f"‚ùå L·ªói khi t√¨m tin t·ª©c: {e}"


def generate_response(model, tokenizer, messages: list, max_new_tokens: int = 512) -> str:
    """Generate response for the current conversation."""
    
    # Apply chat template
    text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True,
        enable_thinking=False
    )
    
    # Tokenize
    inputs = tokenizer(text, return_tensors="pt").to(model.device)
    
    # Generate
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=max_new_tokens,
            do_sample=True,
            temperature=0.7,
            top_p=0.9,
            pad_token_id=tokenizer.eos_token_id
        )
    
    # Decode response (only new tokens)
    response = tokenizer.decode(
        outputs[0][inputs['input_ids'].shape[1]:],
        skip_special_tokens=True
    )
    
    return response.strip()


def detect_search_intent(user_input: str) -> tuple:
    """Detect if user's input requires web search. Returns the user's query for searching."""
    user_lower = user_input.lower()
    
    # Weather patterns
    weather_keywords = ['th·ªùi ti·∫øt', 'weather', 'nhi·ªát ƒë·ªô', 'm∆∞a', 'n·∫Øng', 'ƒë·ªô ·∫©m', 'd·ª± b√°o']
    if any(kw in user_lower for kw in weather_keywords):
        return True, 'weather', f"{user_input} {CURRENT_DATE}"
    
    # News patterns - USE USER'S ACTUAL QUERY
    news_keywords = ['tin t·ª©c', 'tin m·ªõi', 'th·ªùi s·ª±', 's·ª± ki·ªán', 'm·ªõi nh·∫•t', 'h√¥m nay c√≥ g√¨', 'c·∫≠p nh·∫≠t']
    if any(kw in user_lower for kw in news_keywords):
        # Use the user's actual input as search query
        return True, 'news', f"{user_input} {CURRENT_DATE}"
    
    # Price patterns
    price_keywords = ['gi√° v√†ng', 'gi√° xƒÉng', 'gi√° d·∫ßu', 't·ª∑ gi√°', 'ƒë√¥ la', 'usd', 'bitcoin', 'ch·ª©ng kho√°n']
    if any(kw in user_lower for kw in price_keywords):
        return True, 'price', f"{user_input} {CURRENT_DATE}"
    
    # Sports patterns
    sports_keywords = ['b√≥ng ƒë√°', 'v-league', 'world cup', 'k·∫øt qu·∫£', 't·ª∑ s·ªë']
    if any(kw in user_lower for kw in sports_keywords):
        return True, 'sports', f"{user_input} {CURRENT_DATE}"
    
    return False, '', ''


def process_response_with_search(model, tokenizer, messages: list, user_input: str) -> str:
    """Generate response and handle search requests if needed."""
    
    # Check if user's input needs web search
    needs_search, search_type, search_query = detect_search_intent(user_input)
    
    if needs_search and WEB_SEARCH_AVAILABLE:
        print(f"üîç Ph√°t hi·ªán c·∫ßn tra c·ª©u: {search_type}")
        
        # Perform search based on type
        if search_type == 'news':
            search_results = search_news(search_query)
        else:
            search_results = web_search(search_query)
        
        # Create augmented messages with search results
        augmented_messages = messages.copy()
        # Replace last user message with augmented version
        augmented_messages[-1] = {
            "role": "user",
            "content": f"{user_input}\n\n[TH√îNG TIN TRA C·ª®U T·ª™ INTERNET]:\n{search_results}\n\nD·ª±a tr√™n th√¥ng tin tr√™n, h√£y tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa t√¥i m·ªôt c√°ch ng·∫Øn g·ªçn v√† d·ªÖ hi·ªÉu."
        }
        
        response = generate_response(model, tokenizer, augmented_messages)
    else:
        # Normal generation without search
        response = generate_response(model, tokenizer, messages)
        
        # Fallback: Check if model wants to search in response
        search_pattern = r'\[SEARCH:\s*([^\]]+)\]'
        match = re.search(search_pattern, response)
        
        if match and WEB_SEARCH_AVAILABLE:
            search_query = match.group(1).strip()
            
            news_keywords = ['tin t·ª©c', 'tin m·ªõi', 'news', 'th·ªùi s·ª±', 's·ª± ki·ªán']
            if any(kw in search_query.lower() for kw in news_keywords):
                search_results = search_news(search_query)
            else:
                search_results = web_search(search_query)
            
            # Regenerate with search results
            messages.append({
                "role": "assistant",
                "content": f"T√¥i s·∫Ω t√¨m ki·∫øm th√¥ng tin cho b·∫°n..."
            })
            messages.append({
                "role": "user", 
                "content": f"ƒê√¢y l√† k·∫øt qu·∫£ t√¨m ki·∫øm:\n\n{search_results}\n\nH√£y t√≥m t·∫Øt th√¥ng tin n√†y."
            })
            
            response = generate_response(model, tokenizer, messages)
            messages.pop()
            messages.pop()
    
    return response


def print_history(messages: list):
    """Print conversation history (excluding system prompt)."""
    print("\n" + "=" * 60)
    print("üìú L·ªäCH S·ª¨ H·ªòI THO·∫†I:")
    print("=" * 60)
    for msg in messages[1:]:  # Skip system prompt
        role = "üë§ B·∫°n" if msg["role"] == "user" else "ü§ñ Robot"
        print(f"\n{role}:")
        print(f"   {msg['content']}")
    print("=" * 60 + "\n")


def manual_search(query: str):
    """Perform manual search and display results."""
    if not WEB_SEARCH_AVAILABLE:
        print("‚ùå T√≠nh nƒÉng t√¨m ki·∫øm web ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t.")
        print("   H√£y ch·∫°y: pip install duckduckgo-search")
        return
    
    news_keywords = ['tin t·ª©c', 'tin m·ªõi', 'news', 'th·ªùi s·ª±']
    if any(kw in query.lower() for kw in news_keywords):
        results = search_news(query)
    else:
        results = web_search(query)
    
    print(results)


def main():
    """Main interactive chat loop."""
    # Load model
    model, tokenizer = load_model()
    
    # Initialize conversation history with system prompt
    conversation_history = [
        {"role": "system", "content": SYSTEM_PROMPT}
    ]
    
    print("=" * 60)
    print("ü§ñ QWEN3-8B CHAT - H·ªôi tho·∫°i li√™n t·ª•c v·ªõi tra c·ª©u web")
    print("=" * 60)
    print(f"üìÖ Ng√†y h√¥m nay: {CURRENT_DATE}")
    print(f"üåê Tra c·ª©u web: {'‚úÖ ƒê√£ b·∫≠t' if WEB_SEARCH_AVAILABLE else '‚ùå Ch∆∞a c√†i ƒë·∫∑t'}")
    print("=" * 60)
    print("L·ªánh ƒë·∫∑c bi·ªát:")
    print("  ‚Ä¢ 'quit' ho·∫∑c 'exit'    - Tho√°t ch∆∞∆°ng tr√¨nh")
    print("  ‚Ä¢ 'clear'               - X√≥a l·ªãch s·ª≠ h·ªôi tho·∫°i")
    print("  ‚Ä¢ 'history'             - Xem l·ªãch s·ª≠ h·ªôi tho·∫°i")
    print("  ‚Ä¢ 'search: <t·ª´ kh√≥a>'   - T√¨m ki·∫øm th·ªß c√¥ng")
    print("  ‚Ä¢ 'news'                - Xem tin t·ª©c m·ªõi nh·∫•t")
    print("=" * 60 + "\n")
    
    while True:
        try:
            # Get user input
            user_input = input("üë§ B·∫°n: ").strip()
            
            # Handle special commands
            if not user_input:
                continue
            
            if user_input.lower() in ['quit', 'exit', 'tho√°t']:
                print("\nüëã T·∫°m bi·ªát! H·∫πn g·∫∑p l·∫°i!")
                break
            
            if user_input.lower() == 'clear':
                conversation_history = [
                    {"role": "system", "content": SYSTEM_PROMPT}
                ]
                print("üóëÔ∏è ƒê√£ x√≥a l·ªãch s·ª≠ h·ªôi tho·∫°i.\n")
                continue
            
            if user_input.lower() == 'history':
                print_history(conversation_history)
                continue
            
            if user_input.lower().startswith('search:'):
                query = user_input[7:].strip()
                manual_search(query)
                continue
            
            if user_input.lower() == 'news':
                print(search_news("Vi·ªát Nam"))
                continue
            
            # Add user message to history
            conversation_history.append({
                "role": "user",
                "content": user_input
            })
            
            # Generate response with potential web search
            print("\nü§ñ Robot ƒëang suy nghƒ©...")
            response = process_response_with_search(model, tokenizer, conversation_history, user_input)
            
            # Add assistant response to history
            conversation_history.append({
                "role": "assistant",
                "content": response
            })
            
            # Print response
            print(f"\nü§ñ Robot: {response}\n")
            
        except KeyboardInterrupt:
            print("\n\nüëã T·∫°m bi·ªát! H·∫πn g·∫∑p l·∫°i!")
            break
        except Exception as e:
            print(f"\n‚ùå L·ªói: {e}\n")
            continue


if __name__ == "__main__":
    main()
